# üöÄ Execu√ß√£o Paralela com Multithread

## Vis√£o Geral

O sistema agora suporta **execu√ß√£o paralela** de buscas usando **ThreadPoolExecutor** do Python. Isso significa que m√∫ltiplas palavras-chave podem ser buscadas simultaneamente, acelerando significativamente o processo.

## Configura√ß√£o

### Vari√°vel de Ambiente

Adicione ao seu arquivo `.env`:

```bash
# N√∫mero de threads para executar buscas em paralelo (1-10)
# Maior = mais r√°pido, mas consome mais recursos
# Recomendado: 3-5 para melhor performance
SCHEDULER_MAX_WORKERS=3
```

### Valores Recomendados

| Workers | Uso Recomendado | Caracter√≠sticas |
|---------|----------------|-----------------|
| **1** | Testes, recursos limitados | Execu√ß√£o sequencial (sem paralelismo) |
| **3** | **Recomendado** | Balanceamento ideal entre velocidade e recursos |
| **5** | M√°quinas potentes | Maior velocidade, maior consumo de RAM/CPU |
| **10** | Servidores dedicados | M√°xima velocidade poss√≠vel |

## Como Funciona

### Antes (Sequencial)
```
Palavra 1 ‚Üí [====] 30s
Palavra 2 ‚Üí          [====] 30s  
Palavra 3 ‚Üí                   [====] 30s
Total: 90 segundos
```

### Depois (Paralelo com 3 workers)
```
Palavra 1 ‚Üí [====] 30s
Palavra 2 ‚Üí [====] 30s
Palavra 3 ‚Üí [====] 30s
Total: 30 segundos
```

## Ganho de Performance

### Exemplo Real: 9 Palavras-chave

| Workers | Tempo Estimado | Ganho |
|---------|----------------|-------|
| 1 worker | ~4.5 minutos | Baseline |
| 3 workers | ~**1.5 minutos** | **3x mais r√°pido** |
| 5 workers | ~**54 segundos** | **5x mais r√°pido** |

## Implementa√ß√£o T√©cnica

### ThreadPoolExecutor

O sistema usa `concurrent.futures.ThreadPoolExecutor` para:
- Submeter todas as tarefas de busca
- Executar at√© N tarefas simultaneamente (N = MAX_WORKERS)
- Processar resultados conforme completam
- Gerenciar recursos automaticamente

### Thread-Safe

Todos os m√©todos s√£o **thread-safe**:
- ‚úÖ Cada thread executa scraper independente (subprocess)
- ‚úÖ Resultados consolidados ap√≥s todas as threads
- ‚úÖ Logs com identifica√ß√£o da palavra-chave
- ‚úÖ Banco de dados SQLite com controle de concorr√™ncia

## Logs Melhorados

### Logs com Identifica√ß√£o

```
üîç [honda pcx] Iniciando busca OLX...
üîç [onix] Iniciando busca Facebook...
‚úÖ [honda pcx] OLX: 15 encontrados, 3 novos
‚úÖ [onix] Facebook: 20 encontrados, 5 novos
```

### Resumo de Execu√ß√£o

```
üìù 9 palavras-chave encontradas - Usando 3 workers
üìä Resumo OLX: 8 sucessos, 1 erro
üìä Total: 120 encontrados, 15 novos
‚úÖ Busca OLX finalizada em 87.3s (9 palavras com 3 workers)
```

## Recursos do Sistema

### Consumo por Worker

- **CPU**: ~10-15% por worker durante busca
- **RAM**: ~100-200MB por worker (Playwright + Chromium)
- **Rede**: Depende da quantidade de an√∫ncios

### Recomenda√ß√µes de Hardware

| Configura√ß√£o | Max Workers |
|--------------|-------------|
| 2GB RAM, 2 cores | 1-2 |
| 4GB RAM, 4 cores | 3-4 |
| 8GB+ RAM, 6+ cores | 5-10 |

## Monitoramento

### Via Logs

Acompanhe em tempo real:
```bash
tail -f logs/marketplace.log
```

### Via Bot do Telegram

O bot enviar√°:
- Notifica√ß√£o de in√≠cio (com n√∫mero de workers)
- Progresso individual de cada palavra
- Resumo final com estat√≠sticas

## Ajuste Fino

### Otimizar para Velocidade
```bash
SCHEDULER_MAX_WORKERS=5  # Mais threads
```

### Otimizar para Recursos
```bash
SCHEDULER_MAX_WORKERS=2  # Menos threads
```

### Balanceamento
```bash
SCHEDULER_MAX_WORKERS=3  # Ideal (padr√£o)
```

## Troubleshooting

### Muitos Timeouts

**Problema**: Workers em excesso sobrecarregando o sistema

**Solu√ß√£o**: Reduzir MAX_WORKERS
```bash
SCHEDULER_MAX_WORKERS=2
```

### Muito Lento

**Problema**: Poucos workers, execu√ß√£o sequencial

**Solu√ß√£o**: Aumentar MAX_WORKERS
```bash
SCHEDULER_MAX_WORKERS=5
```

### Alto Consumo de RAM

**Problema**: Muitos navegadores Chromium abertos simultaneamente

**Solu√ß√£o**: 
1. Reduzir workers
2. Verificar se h√° processos fantasma do Chromium

```bash
# Windows
taskkill /F /IM chrome.exe

# Linux
pkill chromium
```

## C√≥digo

### Arquivos Modificados

1. **`.env.example`**
   - Adicionado `SCHEDULER_MAX_WORKERS=3`

2. **`src/core/config.py`**
   - Classe `SchedulerConfig` com valida√ß√£o (1-10 workers)

3. **`src/managers/scheduler_manager.py`**
   - M√©todos `_execute_olx_scraper()` e `_execute_facebook_scraper()` thread-safe
   - M√©todos `_run_olx_search()` e `_run_facebook_search()` com ThreadPoolExecutor
   - Logs melhorados com identifica√ß√£o de palavra

## Benef√≠cios

‚úÖ **Velocidade**: At√© 10x mais r√°pido (com 10 workers)  
‚úÖ **Efici√™ncia**: Melhor uso de CPU multi-core  
‚úÖ **Escalabilidade**: Configur√°vel via `.env`  
‚úÖ **Confiabilidade**: Thread-safe e com tratamento de erros  
‚úÖ **Monitoramento**: Logs detalhados e resumo de execu√ß√£o  

## Compara√ß√£o de Cen√°rios

### Cen√°rio 1: 3 Palavras-chave
- **Sequencial**: 90s (1 worker)
- **Paralelo**: 30s (3 workers) - **3x mais r√°pido**

### Cen√°rio 2: 10 Palavras-chave
- **Sequencial**: 300s = 5min (1 worker)
- **Paralelo**: 60s = 1min (5 workers) - **5x mais r√°pido**

### Cen√°rio 3: 20 Palavras-chave
- **Sequencial**: 600s = 10min (1 worker)
- **Paralelo**: 120s = 2min (10 workers) - **5x mais r√°pido**

---

**Vers√£o**: 2.0.1  
**Data**: 31/10/2025  
**Feature**: Multithread com ThreadPoolExecutor
